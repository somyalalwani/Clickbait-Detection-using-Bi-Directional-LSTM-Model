{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80C23X6Tpjxa"
   },
   "source": [
    "## IMPORTING LIBRARIES AND DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SHpEbf7PHOQ8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder  #for label encoding\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "from sklearn.metrics.cluster import homogeneity_score\n",
    "import sys\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HmYegAeAE5l0",
    "outputId": "c26e901a-3fdd-419d-8119-2bddb484fbfe"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t5jV9ZdqMVOX",
    "outputId": "f70f1a4c-3b3f-4c0c-bb8e-1bb27bf953da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24872, 4)\n",
      "(19878, 4)\n"
     ]
    }
   ],
   "source": [
    "#data = pd.read_csv(\"drive/MyDrive/SMAI_PROJECT_CLICKBAIT/train.csv\", na_values='?', header=None,) \n",
    "data = pd.read_csv(\"clickbait-news-detection/train.csv\", na_values='?', header=None,) \n",
    "data.head()\n",
    "print(data.shape)\n",
    "#print(data[2].isna().sum().sum())\n",
    "#\n",
    "df=data.dropna(axis = 0, how ='any')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QJ2OH2z0ja1b",
    "outputId": "71805512-99b5-4862-a484-6419c64d2713"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of            0                                                  1  \\\n",
       "0         id                                              title   \n",
       "1          0  China and Economic Reform: Xi Jinping’s Track ...   \n",
       "2          1  Trade to Be a Big Topic in Theresa May’s U.S. ...   \n",
       "3          2  The Top Beaches In The World, According To Nat...   \n",
       "4          3  Sheriff’s Report Provides New Details on Tamir...   \n",
       "...      ...                                                ...   \n",
       "24867  24866                                                NaN   \n",
       "24868  24867  Unable to Enter U.S., and Still Stranded Abroa...   \n",
       "24869  24868  Calais Migrant Camp Will Be Demolished Soon, F...   \n",
       "24870  24869  Twitter’s NFL Deal No Cure for User and Advert...   \n",
       "24871  24870  Five or Six Things I Didn’t Know About Brad Pi...   \n",
       "\n",
       "                                                       2          3  \n",
       "0                                                   text      label  \n",
       "1      Economists generally agree: China must overhau...       news  \n",
       "2      LONDON—British Prime Minister Theresa May said...       news  \n",
       "3      Beaches come in all sorts of shapes and sizes ...  clickbait  \n",
       "4      A timeline of what happened after Tamir Rice, ...  clickbait  \n",
       "...                                                  ...        ...  \n",
       "24867  Because the success of the individual is very ...      other  \n",
       "24868  AMSTERDAM — Pedram Paragomi, a Iranian medical...       news  \n",
       "24869  (AFP) — The total dismantling of the “Jungle” ...       news  \n",
       "24870  Gaining the worldwide rights to stream 10 NFL ...       news  \n",
       "24871  The worst kind, too. The kind who lets a plant...       news  \n",
       "\n",
       "[24872 rows x 4 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1svuxWryjm26",
    "outputId": "8402a0b2-45d6-48c8-bc51-89a2610a5fc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of            0                                                  1  \\\n",
       "0         id                                              title   \n",
       "1          0  China and Economic Reform: Xi Jinping’s Track ...   \n",
       "2          1  Trade to Be a Big Topic in Theresa May’s U.S. ...   \n",
       "3          2  The Top Beaches In The World, According To Nat...   \n",
       "4          3  Sheriff’s Report Provides New Details on Tamir...   \n",
       "...      ...                                                ...   \n",
       "19873  24864  A very interesting user generated content website   \n",
       "19874  24867  Unable to Enter U.S., and Still Stranded Abroa...   \n",
       "19875  24868  Calais Migrant Camp Will Be Demolished Soon, F...   \n",
       "19876  24869  Twitter’s NFL Deal No Cure for User and Advert...   \n",
       "19877  24870  Five or Six Things I Didn’t Know About Brad Pi...   \n",
       "\n",
       "                                                       2          3  \n",
       "0                                                   text      label  \n",
       "1      Economists generally agree: China must overhau...       news  \n",
       "2      LONDON—British Prime Minister Theresa May said...       news  \n",
       "3      Beaches come in all sorts of shapes and sizes ...  clickbait  \n",
       "4      A timeline of what happened after Tamir Rice, ...  clickbait  \n",
       "...                                                  ...        ...  \n",
       "19873                         let me know what you think      other  \n",
       "19874  AMSTERDAM — Pedram Paragomi, a Iranian medical...       news  \n",
       "19875  (AFP) — The total dismantling of the “Jungle” ...       news  \n",
       "19876  Gaining the worldwide rights to stream 10 NFL ...       news  \n",
       "19877  The worst kind, too. The kind who lets a plant...       news  \n",
       "\n",
       "[19878 rows x 4 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.reset_index(drop=True)\n",
    "df.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ysg6j4nhPACv"
   },
   "source": [
    "#PREPROCESSING OF DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NnqL2V8aThW-"
   },
   "outputs": [],
   "source": [
    "a=df.iloc[1:,2]\n",
    "b=df.iloc[1:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,3] = df.iloc[:,3].str.replace('news','1')\n",
    "df.iloc[:,3] = df.iloc[:,3].str.replace('clickbait','0')\n",
    "\n",
    "y_actual=df.iloc[1:,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of 1            1\n",
       "2            1\n",
       "3            0\n",
       "4            0\n",
       "5            1\n",
       "         ...  \n",
       "19873    other\n",
       "19874        1\n",
       "19875        1\n",
       "19876        1\n",
       "19877        1\n",
       "Name: 3, Length: 19877, dtype: object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxuFHznGPDoL"
   },
   "source": [
    "1. Converting all sentences to lower case \n",
    "2. Writing Abbreviations in full form\n",
    "3. Removing punctuations (Normalisation)\n",
    "4. Removing Stop words (Normalisation)\n",
    "5. Lemmatizing the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xa6DBTYWTfAb"
   },
   "outputs": [],
   "source": [
    "contractions = {\n",
    "\"ain't\": \"am not\", \"aren't\": \"are not\", \"can't\": \"cannot\", \"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\", \"he'll\": \"he will\", \"he'll've\": \"he will have\", \"he's\": \"he is\",\n",
    "\"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\"i'd\": \"I would\", \"i'd've\": \"I would have\", \"i'll\": \"I will\", \"i'll've\": \"I will have\",\n",
    "\"i'm\": \"I am\", \"i've\": \"I have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\", \"it's\": \"it is\",\n",
    "\"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\", \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\", \"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\", \"so've\": \"so have\", \"so's\": \"so is\", \"that'd\": \"that had\",\n",
    "\"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\", \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \"what's\": \"what is\",\n",
    "\"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\",\n",
    "\"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why has\", \"why've\": \"why have\",\n",
    "\"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\", \"y'all're\": \"you all are\", \"y'all've\": \"you all have\", \"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = BeautifulSoup(ihtml.unescape(text)).text\n",
    "    text = re.sub(r\"http[s]?://\\S+\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GAkmRAQyUkUm",
    "outputId": "3f8ceddd-0a8c-4af0-bd7d-d209b7412ab5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: pip: command not found\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/somyalalwani9/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/somyalalwani9/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/somyalalwani9/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing stop words\n",
    "!pip install nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nBCdGWiRmD1b",
    "outputId": "9fd3bb3e-6ce3-4f59-e80d-ffcac890577f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1        Economists generally agree: China must overhau...\n",
      "2        LONDON—British Prime Minister Theresa May said...\n",
      "3        Beaches come in all sorts of shapes and sizes ...\n",
      "4        A timeline of what happened after Tamir Rice, ...\n",
      "5        An Italian neurosurgeon who has claimed for mo...\n",
      "                               ...                        \n",
      "19873                           let me know what you think\n",
      "19874    AMSTERDAM — Pedram Paragomi, a Iranian medical...\n",
      "19875    (AFP) — The total dismantling of the “Jungle” ...\n",
      "19876    Gaining the worldwide rights to stream 10 NFL ...\n",
      "19877    The worst kind, too. The kind who lets a plant...\n",
      "Name: 2, Length: 19877, dtype: object\n",
      "A video has emerged of an 83-year-old man dancing energetically to music at an electronic dance festival in the Netherlands. In the footage, captured by a bystander at Edit Festival in Haarlem, Johan de Vries can be seen dancing in front of crowds of young revellers. Known locally as the ‘Grandfather of House’, Johan has been showcasing his dance skills at festivals for several years and, according to local news reports, used to be a ballroom dancer. “No wonder Holland is the number one country when it comes to electronic dance-music,” the filmer later wrote online. “Dance is in the genes of the Dutch. At Edit Festival in Haarlem, where international DJ's like Sasha, Danny Howels and the guys from Slam performed, this 83-year old man knew the moves. \"Oh Yeah! Upon asking what he thought of the festival he said: ‘It's still early. I am waiting for the DJ's who play harder music”. 10 Jun 2015 10 Jun 2015 10 Jun 2015 10 Jun 2015 10 Jun 2015 10 Jun 2015 30 Mar 2016 30 Mar 2016\n",
      "1        China and Economic Reform: Xi Jinping’s Track ...\n",
      "2        Trade to Be a Big Topic in Theresa May’s U.S. ...\n",
      "3        The Top Beaches In The World, According To Nat...\n",
      "4        Sheriff’s Report Provides New Details on Tamir...\n",
      "5        Surgeon claiming he will transplant volunteer'...\n",
      "                               ...                        \n",
      "19873    A very interesting user generated content website\n",
      "19874    Unable to Enter U.S., and Still Stranded Abroa...\n",
      "19875    Calais Migrant Camp Will Be Demolished Soon, F...\n",
      "19876    Twitter’s NFL Deal No Cure for User and Advert...\n",
      "19877    Five or Six Things I Didn’t Know About Brad Pi...\n",
      "Name: 1, Length: 19877, dtype: object\n",
      "Old man dances at Dutch electronic dance festival\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(a[41])\n",
    "print(b)\n",
    "print(b[41])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "OKVZXMLGX9kl"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "final_lines=[]\n",
    "final_headings=[]\n",
    "for line in range(1,int(0.7*len(a))):\n",
    "  #print(a[line])\n",
    "  #print(type(a[line]))\n",
    "  #print(\"*********\")\n",
    "  a[line]=(a[line]).lower()     #Converting all sentences to lower case \n",
    "  for word in a[line].split():\n",
    "    if word in contractions:\n",
    "        a[line]=a[line].replace(word, contractions[word.lower()])  #Writing Abbreviations in full form\n",
    "  tokens = word_tokenize(a[line].lower()) \n",
    "  words = [word for word in tokens if word.isalpha()]    #Removing punctuations\n",
    "  final_word = [w for w in words if not w in stop_words]     #Removing Stop words \n",
    "  final_words = [lemmatizer.lemmatize(w) for w in final_word]     #Lemmatizing words\n",
    "  ans=\"\"\n",
    "  for x in final_words:\n",
    "    ans= ans+ \" \"+x\n",
    "  final_lines.append(ans.lstrip())\n",
    "  b[line]=(b[line]).lower()     #Converting all sentences to lower case \n",
    "  for word in b[line].split():\n",
    "    if word in contractions:\n",
    "        b[line]=b[line].replace(word, contractions[word.lower()])  #Writing Abbreviations in full form\n",
    "  tokens = word_tokenize(b[line].lower()) \n",
    "  words = [word for word in tokens if word.isalpha()]    #Removing punctuations\n",
    "  final_head = [w for w in words if not w in stop_words]     #Removing Stop words \n",
    "  final_heads = [lemmatizer.lemmatize(w) for w in final_head]     #Lemmatizing words\n",
    "  ans=\"\"\n",
    "  for x in final_heads:\n",
    "    ans= ans+ \" \"+x\n",
    "  final_headings.append(ans.lstrip())\n",
    "#print(final_lines[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MaYc-zT8fKZb",
    "outputId": "78fd246b-c917-4a34-fdfe-5fa5c8bb5347"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "economist generally agree china must overhaul huge wasteful economy want continue grow year come mean limiting political interference banking financial system making bloated industry sensitive market force lowering barrier foreign trade investment proponent took heart late president xi jinping took formal control chinese communist party pledge crack corruption cut red tape today xi nears end first term much optimism among economist faded china remains heavily dependent large investment maintained brisk slowing economic growth steep rise lending still administration made small change hint xi may focus economic overhaul start second term xi done far important done reform expert give credit china move currency beijing persuaded international monetary fund admit currency renminbi elite club currency central bank hold reserve win approval china made much easier move money country shifted daily pegging renminbi dollar slightly system lingering problem move doubt lately opening money flow led many chinese family company send money country renminbi weakened dollar chinese government spend nearly trillion prop past month beijing reimposed many restriction sending money country reform faced early last year huge supply unsold real estate stalling construction beijing decided make much easier bank issue mortgage set buying frenzy big city slightly pared backlog empty apartment lingering problem looked like bubble look like one even beijing shanghai already world highest real estate price relation local income developer still heavily debt reform china made limited move allow foreigner trade extensively bond market hedge currency risk connect stock market shanghai shenzhen hong kong long served china financial gateway rest world local government discouraged setting company borrow heavily pay public work lingering problem move open overshadowed tighter government control stock market crash major stock market index passed including chinese stock citing need improvement new partnership emerged continue china borrowing spree chinese official hoped private partner would force local government make wiser cautious investment initial private partner tended enterprise typically share local government interest borrowing heavily create job reform china moved help bank plagued rising tide bad loan bank allowed swap unpaid loan equity stake troubled borrower asset management company buying bad loan bank bank given growing discretion set interest rate based creditworthiness borrower interest rate bank pay deposit deregulated allowing competition among bank benefit depositor lingering problem move enough bank still face large overhang loan company little hope repayment bank continue roll loan troubled borrower extend huge loan politically connected borrower including influential private company well enterprise economy slow sharply mountain bad loan grow much time entrepreneur continue complain system denies access cheap money need grow reform china modestly reduced capacity lingering problem lot work china still roughly capacity rest world combined china still many coal mine given plan shift solar wind nuclear energy many industrial sector intense competition slowing economic growth curbed private investment reform pay limited top executive enterprise merged notably rail equipment limit extent compete one another overseas sale lingering problem china company remain bloated inefficient monopoly oligopoly continue dominate large sector economy like telecommunication power transmission enterprise sector like steel making coal mining tend focus mainly preserving employment worker matter much money need borrow bank cover financial loss pay limit may drive talented leader private sector reform faced shrinking labor force population rapidly graying xi ended china notorious policy fine forced abortion government even begun mulling whether offer incentive family second child lingering problem labor force continue shrink decade presenting serious drag economic growth reform government made easier migrant worker rural area obtain residency access social benefit smaller city government preparing move municipal bureaucracy beijing end year outlying suburb part experiment aimed testing whether build satellite city around major metropolitan center lingering problem rural migrant still little hope gaining residency big city like beijing shanghai without residency access medical insurance education child benefit limited\n",
      "prime minister theresa may said discus trade security coming meeting president donald trump first visit foreign leader president underscoring significance country relationship britain longtime ally seeking build tie leaf european union may key objective visit washington friday lay\n",
      "beach come sort shape size beyond typical caribbean postcard national geographic new list top beach world includes diverse mix shoreline around globe caribbean number beauty iceland spot austral coast highlight include head national geographic rest top beach world correction previous version post incorrectly identified photo lazy beach photo replaced title updated reflect lazy beach island koh rong samloem koh rong\n",
      "china economic reform xi jinping track record\n",
      "trade big topic theresa may visit\n",
      "top beach world according national geographic\n"
     ]
    }
   ],
   "source": [
    "#print(final_lines[679])\n",
    "print(final_lines[0])\n",
    "print(final_lines[1])\n",
    "print(final_lines[2])\n",
    "\n",
    "print(final_headings[0])\n",
    "print(final_headings[1])\n",
    "print(final_headings[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n",
    "del df\n",
    "del tokens\n",
    "del words\n",
    "del final_word\n",
    "del final_words\n",
    "del final_head\n",
    "del final_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Y-H7i2Saz1E",
    "outputId": "386198a9-a51a-4850-f449-bb6479b0beca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(final_lines)\n",
    "Y = vectorizer.fit_transform(final_headings)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "  (0, 24799)\t2\n",
      "  (0, 32101)\t1\n",
      "  (0, 1498)\t1\n",
      "  (0, 14666)\t13\n",
      "  (0, 55419)\t1\n",
      "  (0, 60136)\t2\n",
      "  (0, 38070)\t3\n",
      "  (0, 90187)\t1\n",
      "  (0, 24800)\t3\n",
      "  (0, 90018)\t1\n",
      "  (0, 17386)\t6\n",
      "  (0, 34312)\t3\n",
      "  (0, 92715)\t3\n",
      "  (0, 16402)\t1\n",
      "  (0, 51801)\t1\n",
      "  (0, 47779)\t1\n",
      "  (0, 63709)\t1\n",
      "  (0, 40554)\t1\n",
      "  (0, 6488)\t1\n",
      "  (0, 29165)\t3\n",
      "  (0, 81284)\t3\n",
      "  (0, 49821)\t2\n",
      "  (0, 9204)\t2\n",
      "  (0, 39801)\t1\n",
      "  (0, 74002)\t1\n",
      "  :\t:\n",
      "  (0, 71309)\t2\n",
      "  (0, 4190)\t1\n",
      "  (0, 58492)\t1\n",
      "  (0, 69231)\t3\n",
      "  (0, 77055)\t1\n",
      "  (0, 76600)\t1\n",
      "  (0, 64643)\t1\n",
      "  (0, 55217)\t1\n",
      "  (0, 11603)\t1\n",
      "  (0, 59909)\t1\n",
      "  (0, 80036)\t1\n",
      "  (0, 61150)\t1\n",
      "  (0, 27549)\t1\n",
      "  (0, 1635)\t1\n",
      "  (0, 82741)\t1\n",
      "  (0, 11419)\t1\n",
      "  (0, 72441)\t1\n",
      "  (0, 4407)\t1\n",
      "  (0, 52635)\t1\n",
      "  (0, 13672)\t1\n",
      "  (0, 31394)\t1\n",
      "  (0, 91624)\t1\n",
      "  (0, 51909)\t1\n",
      "  (0, 40432)\t1\n",
      "  (0, 24933)\t1\n"
     ]
    }
   ],
   "source": [
    "print(type(X))\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "cabcxx5dvkSN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#print(vectorizer.get_feature_names())\n",
    "#final_word_vector = X.toarray()\n",
    "#final_heading_vector= Y.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "final_word_vector=[]\n",
    "\n",
    "i=0\n",
    "while (i<X.shape[0] and i+10000<X.shape[0]):\n",
    "    final_word_vector.extend(X[i:i+10000].toarray())\n",
    "    i+=10000\n",
    "\n",
    "final_word_vector.extend(X[i:].toarray())\n",
    "\n",
    "\n",
    "final_heading_vector=[]\n",
    "\n",
    "i=0\n",
    "while (i<Y.shape[0] and i+10000<Y.shape[0]):\n",
    "    final_heading_vector.extend(Y[i:i+10000].toarray())\n",
    "    i+=10000\n",
    "\n",
    "final_heading_vector.extend(Y[i:].toarray())\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4457\n",
      "374\n",
      "94049\n"
     ]
    }
   ],
   "source": [
    "print(len(final_lines[0]))\n",
    "#print(final_lines[0])\n",
    "print(np.count_nonzero(final_word_vector[0]))\n",
    "print(len(final_word_vector[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "AGBrLskqhAAT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4457\n",
      "374\n",
      "94049\n"
     ]
    }
   ],
   "source": [
    "print(len(final_lines[0]))\n",
    "#print(final_lines[0])\n",
    "print(np.count_nonzero(final_word_vector[0]))\n",
    "print(len(final_word_vector[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "6YanGwhJykX2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "7\n",
      "15672\n"
     ]
    }
   ],
   "source": [
    "print(len(final_headings[0]))\n",
    "#print(final_lines[0])\n",
    "print(np.count_nonzero(final_heading_vector[0]))\n",
    "print(len(final_heading_vector[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-b0f94e0c0aa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_heading_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfinal_heading_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_heading_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_heading_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_heading_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_heading_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(final_heading_vector.shape)\n",
    "final_heading_vector = final_heading_vector.reshape(1, final_heading_vector.shape[0], final_heading_vector.shape[1])\n",
    "print(final_heading_vector.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_word_vector.shape)\n",
    "final_word_vector = final_word_vector.reshape(1, final_word_vector.shape[0], final_word_vector.shape[1])\n",
    "print(final_word_vector.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_heading_vector.shape)\n",
    "print(final_word_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install keras\n",
    "!pip3 install tenserflow\n",
    "!pip3 install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, MaxPool1D, Dropout, Dense, GlobalMaxPooling1D, Embedding, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#!pip3 uninstall protobuf\n",
    "#!pip3 uninstall google\n",
    "#!pip3 install google\n",
    "#!pip3 install protobuf\n",
    "#!pip3 install google-cloud\n",
    "\n",
    "import tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.add(Bidirectional(LSTM(2, return_sequences=True), input_shape=(13912,15672)))\n",
    "#model.add(TimeDistributed(Dense(2, activation='sigmoid')))\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\"\"\"\n",
    "# train LSTM\n",
    "for epoch in range(1000):\n",
    "\t# generate new random sequence\n",
    "\tX,y = get_sequence(n_timesteps)\n",
    "\t# fit model for one epoch on this sequence\n",
    "\tmodel.fit(X, y, epochs=1, batch_size=1, verbose=2)\n",
    "# evaluate LSTM\n",
    "X,y = get_sequence(n_timesteps)\n",
    "yhat = model.predict_classes(X, verbose=0)\n",
    "for i in range(n_timesteps):\n",
    "\tprint('Expected:', y[0, i], 'Predicted', yhat[0, i])\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SMAI PROJECT.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
